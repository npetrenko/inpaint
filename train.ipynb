{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from train_config import TrainConfig\n",
    "from utils import TBImUploader, get_new_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_dropout = tf.placeholder(tf.bool, [], \"disc_dropout\")\n",
    "disc_batchnorm = tf.placeholder(tf.bool, [], \"disc_batchnorm\")\n",
    "dec_learning_phase = tf.placeholder(tf.bool, [], \"dec_learning_phase\")\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "train_config = TrainConfig(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_config.model_type == \"dense\":\n",
    "    from models.dense import DecoderModel, DiscriminatorModel\n",
    "elif train_config.model_type == \"conv\":\n",
    "    from models.conv import DecoderModel, DiscriminatorModel\n",
    "else:\n",
    "    raise RuntimeError(\"Unknown model type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "    true_data = train_dataset.concatenate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x -= 125.\n",
    "    x /= 125.\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    train_dataset = train_dataset.shuffle(x_train.shape[0], reshuffle_each_iteration=False)\\\n",
    "    .shuffle(1024).batch(train_config.batch_size).map(preprocess)\n",
    "    \n",
    "    test_dataset = test_dataset.shuffle(x_test.shape[0], reshuffle_each_iteration=False)\\\n",
    "    .batch(256).map(preprocess)\n",
    "\n",
    "    handle = tf.placeholder(tf.string, [])\n",
    "    iterator = tf.data.Iterator.from_string_handle(handle, \n",
    "                                                   train_dataset.output_types, \n",
    "                                                   train_dataset.output_shapes)\n",
    "\n",
    "    train_iterator = train_dataset.make_initializable_iterator()\n",
    "    test_iterator = test_dataset.make_initializable_iterator()\n",
    "    \n",
    "    next_elt = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "test_handle = sess.run(test_iterator.string_handle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_elt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(train_iterator.initializer)\n",
    "sess.run(test_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.layers as tfl\n",
    "import tensorflow.keras.layers as kerasl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = DecoderModel(dec_learning_phase, train_config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder/Reshape:0' shape=(100, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_model(tf.zeros([100, train_config.latent_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = DiscriminatorModel(disc_dropout, disc_batchnorm, train_config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_config.loss_type == \"scientific\":\n",
    "    from losses.scientific import build_gan_losses\n",
    "elif train_config.loss_type == \"working\":\n",
    "    from losses.working import build_gan_losses\n",
    "else:\n",
    "    raise RuntimeError(\"Unknown loss type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_gain, disc_gain = build_gan_losses(decoder_model, discriminator_model, next_elt, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan_update():\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "\n",
    "#     def build_update(gain, variables):\n",
    "#         grads = tf.gradients(gain, variables)\n",
    "#         grads = map(lambda x: tf.clip_by_value(x, -5., 5.), grads)\n",
    "#         grads_and_vars = [(x,y) for x,y in zip(grads, variables) if x != None]\n",
    "#         return opt.apply_gradients(grads_and_vars)\n",
    "    \n",
    "#     decoder_upd = build_update(dec_gain, decoder_model.get_variables())\n",
    "#     disc_upd = build_update(disc_gain, discriminator_model.get_variables())\n",
    "    decoder_upd = opt.minimize(-dec_gain, var_list=decoder_model.get_variables())\n",
    "    disc_upd = opt.minimize(-disc_gain, var_list=discriminator_model.get_variables())\n",
    "    return (decoder_upd, disc_upd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_summaries = decoder_model.get_merged_summaries()\n",
    "disc_summaries = discriminator_model.get_merged_summaries()\n",
    "\n",
    "writer = tf.summary.FileWriter(get_new_dir(\"/home/nikita/tmp/gan_logs/\", \"{}_{}_\".format(train_config.model_type, \n",
    "                                                                                         train_config.loss_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_upd, disc_upd = build_gan_update()\n",
    "global_step_upd = global_step.assign_add(1)\n",
    "\n",
    "decoder_upd = [decoder_upd, global_step_upd]\n",
    "disc_upd = [disc_upd, global_step_upd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_initializer = tf.global_variables_initializer()\n",
    "sess.run(variable_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "num_images = 6\n",
    "\n",
    "noise = np.random.normal(size=[num_images,train_config.latent_dim]).astype(np.float32)\n",
    "ggg = decoder_model(tf.constant(noise))\n",
    "        \n",
    "im_summarizer = TBImUploader(decoder_model, train_config, 6)\n",
    "    \n",
    "def show_pics():\n",
    "    arr = sess.run(ggg, {dec_learning_phase: False})\n",
    "    arr = np.concatenate([arr[i] for i in range(arr.shape[0])], axis=1)\n",
    "    plt.imshow(arr[...,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'disc_rate': [0.7, 1.0], 'dec_rate': [1.0, 0.7], 'batch_size': 256, 'disc_init_steps': 30000, 'dec_init_steps': 30000, 'label_noise_rate': 0.2, 'disc_BN': True, 'dec_BN': True, 'latent_dim': 32, 'loss_type': 'scientific', 'model_type': 'dense', 'disc_dropout_during_dec_training': True}\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config_summ = tf.summary.text(\"train_config\", tf.constant(train_config.to_string()))\n",
    "writer.add_summary(train_config_summ.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "dec_dic = {handle: train_handle, \n",
    "           dec_learning_phase: True, \n",
    "           disc_dropout: train_config.disc_dropout_during_dec_training,\n",
    "           disc_batchnorm: True}\n",
    "\n",
    "disc_dic = {handle: train_handle, \n",
    "            dec_learning_phase: True, \n",
    "            disc_dropout: True,\n",
    "            disc_batchnorm: True}\n",
    "\n",
    "# dec_dic = {handle: train_handle, dec_learning_phase: False, disc_learning_phase: False}\n",
    "# disc_dic = {handle: train_handle, dec_learning_phase: False, disc_learning_phase: False}\n",
    "\n",
    "for epoch in range(100000):\n",
    "    if epoch % 10 == 0:\n",
    "        show_pics()\n",
    "    \n",
    "    im_summarizer.post_summary()\n",
    "    counter = 0\n",
    "    try:\n",
    "        while True:\n",
    "            if random.random() < train_config.get_disc_rate():\n",
    "                _, summ = sess.run([disc_upd, disc_summaries], disc_dic)\n",
    "                if counter % 100 == 0:\n",
    "                    writer.add_summary(summ, global_step.eval())\n",
    "            \n",
    "            if random.random() < train_config.get_dec_rate():\n",
    "                _, summ = sess.run([decoder_upd, dec_summaries], dec_dic)\n",
    "                if counter % 100 == 0:\n",
    "                    writer.add_summary(summ, global_step.eval())\n",
    "            counter += 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        sess.run(train_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(variable_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
